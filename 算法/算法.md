#### 问题
+ 1g(1024000k) 大小文件，里面每行是最大 16k 的单词，限制内存 1m，统计单词频率最多的 100 个单词？
+ 一亿个数据选取其中最大1000条？
+ 5TB的硬盘上放满了数据，请写一个算法将这些数据进行排重。如果这些数据是一些 32 bit 大小的数据该如何解决？如果是 64 bit 的呢？
+ 50 杯水中有一杯有毒，老鼠喝后一小时会死，想一小时知道哪杯有毒，需要多少只老鼠？
+ leetcode236 题，给两个节点，找树的最近公共父节点，更优解呢？



#### 答案

+ 1g(1024000k) 大小文件，里面每行是最大 16k 的单词，限制内存 1m，统计单词频率最多的 100 个单词？

  分治+hash+堆
  分治：顺序读取文件，对于每个单词，hash(单词)%5000，存到5000个小文件中，每个文件大约200k,如果有超过1M大小的文件，就继续往下分，直到
  分解的文件大小不超过1M
  哈希：使用HashMap统计每个小文件中单词出现的频率
  堆：使用堆排序取出每个文件频率最大的100个词，又得到5000个文件，然后对这5000个文件归并取出Top100。


+ 一亿个数据选取其中最大1000条？
+ 5TB的硬盘上放满了数据，请写一个算法将这些数据进行排重。如果这些数据是一些 32 bit 大小的数据该如何解决？如果是 64 bit 的呢？
+ 50杯水中有一杯有毒，老鼠喝后一小时会死，想一小时知道哪杯有毒，需要多少只老鼠？
+ leetcode236题，给两个节点，找树的最近公共父节点，更优解呢？
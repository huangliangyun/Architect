#### 问题
+ 1g (1024000k)  大小文件，里面每行是最大 16k 的单词，限制内存 1m，统计单词频率最多的 100 个单词？
+ 一亿个数据选取其中最大 1000 条 (TOP K 问题 ) ？
+ 5 TB 的硬盘上放满了数据，请写一个算法将这些数据进行排重。如果这些数据是一些 32 bit 大小的数据该如何解决？如果是 64 bit 的呢？
+ 50 杯水中有一杯有毒，老鼠喝后一小时会死，想一小时知道哪杯有毒，需要多少只老鼠？
+ leetcode236 题，给两个节点，找树的最近公共父节点，更优解呢？
+ 什么是一致性 Hash 算法？



#### 答案

+ 1g(1024000k) 大小文件，里面每行是最大 16k 的单词，限制内存 1m，统计单词频率最多的 100 个单词？

  分治 + hash + 堆  
  分治：顺序读取文件，对于每个单词，hash(单词)%5000，存到5000个小文件中，每个文件大约200k,如果有超过1M大小的文件，就继续往下分，直到分解的文件大小不超过1M  
  哈希：使用HashMap统计每个小文件中单词出现的频率  
  堆：使用堆排序取出每个文件频率最大的100个词，又得到5000个文件，然后对这5000个文件归并取出Top100。    


+ 一亿个数据选取其中最大 1000 条 (TOP K 问题 ) ？  

  1、排序，时间复杂度O(nlogn)   
  2、快排 Partition 划分思想，每次划分，如果中间值等于 K ，那么左边或者右边的数就是 Top K，如果不等于，只需要递归左边或者右边即可，第一次遍历数组需要花费 n，然后每遍历一次折半，n+n/2+n/4,时间复杂度为 O(n)，缺点是内存问题，在海量数据情况下，无法一次加载到内存中。  
  3、利用分布式思想，把数据分散在多台机器中，每台机器计算各自的 Top K 数据，然后汇总，计算最终的 Top K 数据。  
  4、维护一个大小为 K 的小顶堆，依次将数据放入堆中，当堆满的时候，只需要将堆顶元素与下一个数比较，如果大于堆顶元素，则将当前堆顶元素抛弃，将该元素插入堆中，遍历完后，TOP K 数据就在堆里面了。    
  https://www.jianshu.com/p/a4a1984fc4ff
  
  
  
+ 5TB的硬盘上放满了数据，请写一个算法将这些数据进行排重。如果这些数据是一些 32 bit 大小的数据该如何解决？如果是 64 bit 的呢？

+ 50杯水中有一杯有毒，老鼠喝后一小时会死，想一小时知道哪杯有毒，需要多少只老鼠？

+ leetcode236题，给两个节点，找树的最近公共父节点，更优解呢？

+ 什么是一致性 Hash 算法？
  https://zhuanlan.zhihu.com/p/34985026
  https://www.jianshu.com/p/b398250d661a

  